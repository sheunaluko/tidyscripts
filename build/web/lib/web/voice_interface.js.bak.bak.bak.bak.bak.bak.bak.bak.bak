/*
 Main voice interface for controlling speech recognition and tts at high level
 */
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __generator = (this && this.__generator) || function (thisArg, body) {
    var _ = { label: 0, sent: function() { if (t[0] & 1) throw t[1]; return t[1]; }, trys: [], ops: [] }, f, y, t, g;
    return g = { next: verb(0), "throw": verb(1), "return": verb(2) }, typeof Symbol === "function" && (g[Symbol.iterator] = function() { return this; }), g;
    function verb(n) { return function (v) { return step([n, v]); }; }
    function step(op) {
        if (f) throw new TypeError("Generator is already executing.");
        while (_) try {
            if (f = 1, y && (t = op[0] & 2 ? y["return"] : op[0] ? y["throw"] || ((t = y["return"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;
            if (y = 0, t) op = [op[0] & 2, t.value];
            switch (op[0]) {
                case 0: case 1: t = op; break;
                case 4: _.label++; return { value: op[1], done: false };
                case 5: _.label++; y = op[1]; op = [0]; continue;
                case 7: op = _.ops.pop(); _.trys.pop(); continue;
                default:
                    if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) { _ = 0; continue; }
                    if (op[0] === 3 && (!t || (op[1] > t[0] && op[1] < t[3]))) { _.label = op[1]; break; }
                    if (op[0] === 6 && _.label < t[1]) { _.label = t[1]; t = op; break; }
                    if (t && _.label < t[2]) { _.label = t[2]; _.ops.push(op); break; }
                    if (t[2]) _.ops.pop();
                    _.trys.pop(); continue;
            }
            op = body.call(thisArg, _);
        } catch (e) { op = [6, e]; y = 0; } finally { f = t = 0; }
        if (op[0] & 5) throw op[1]; return { value: op[0] ? op[1] : void 0, done: true };
    }
};
import * as sr from "./speech_recognition";
import * as tts from "./tts";
import * as ap from "./audio_processing";
/*
 audio_processing.ts    | connects to microphone and detects when there is sound occuring
 speech_recognition.ts  | starts and stops speech recognition and provides recognition results
 tts.ts                 | will perform speech synthesis given a string
 
 This file combines the three aforementioned libraries to create an out of the box seamless
 voice/ tts experience.
 
 The audio processor is used to detect when a spike in volume has occured, and it triggers
 the speech recognizer to start listening.
 
 When the tts.speak function is called, the speech recognizer is automatically paused until tts
 has finished.
 
 To use, simply call initialize_recognition() , and the recognition results will be available by
 listending to the window.addEventListener( 'tidyscripts_web_speech_recognition_result' , (e) => e.detail ) handler
 
 For tts, call speak(text)
 
 
*/
export var recognition = null;
export var RecognitionState;
(function (RecognitionState) {
    RecognitionState["NULL"] = "NULL";
    RecognitionState["PAUSED"] = "PAUSED";
    RecognitionState["LISTENING"] = "LISTENING";
})(RecognitionState || (RecognitionState = {}));
export var recognition_state = RecognitionState.NULL;
export function initialize_recognition(ops) {
    ops = ops || {};
    var old_on_end = ops.onEnd;
    ops.onEnd = function () {
        recognition_state = RecognitionState.PAUSED;
        console.log("Recognition ended");
        old_on_end ? old_on_end() : null;
    };
    recognition = sr.get_recognition_object(ops);
    recognition_state = RecognitionState.PAUSED;
    //now we start the audio detector
    ap.audio_detector(start_recognition);
    return;
}
export function pause_recognition() {
    if (recognition) {
        recognition.abort();
        recognition_state = RecognitionState.PAUSED;
    }
}
export function stop_recognition() {
    if (recognition) {
        recognition.abort();
        recognition = null;
        recognition_state = RecognitionState.NULL;
    }
    ap.stop();
}
export function start_recognition() {
    return __awaiter(this, void 0, void 0, function () {
        return __generator(this, function (_a) {
            //if tts is speaking then we should wait 
            if (recognition_state == RecognitionState.LISTENING) {
                //console.log("Already listening")
                return [2 /*return*/];
            }
            if (tts.is_speaking()) {
                console.log("Wont start recognition while tts active");
            }
            if (recognition) {
                recognition.start();
            }
            else {
                initialize_recognition();
                console.log("Recognition initialized without args");
            }
            recognition_state = RecognitionState.LISTENING;
            return [2 /*return*/];
        });
    });
}
export function stop_recognition_and_detection() {
    var ap_thresh = ap.detection_threshold;
    pause_recognition();
    ap.set_detection_threshold(Infinity); //stop the detection 
    return ap_thresh;
}
export function start_recognition_and_detection(t) {
    start_recognition();
    ap.set_detection_threshold(t);
}
export function speak(text) {
    return __awaiter(this, void 0, void 0, function () {
        var thresh;
        return __generator(this, function (_a) {
            switch (_a.label) {
                case 0:
                    if (!recognition) return [3 /*break*/, 2];
                    thresh = stop_recognition_and_detection();
                    tts.speak({ text: text });
                    return [4 /*yield*/, tts.finished_speaking()];
                case 1:
                    _a.sent();
                    start_recognition_and_detection(thresh);
                    return [3 /*break*/, 4];
                case 2:
                    tts.speak({ text: text });
                    return [4 /*yield*/, tts.finished_speaking()];
                case 3:
                    _a.sent();
                    _a.label = 4;
                case 4: return [2 /*return*/];
            }
        });
    });
}
//# sourceMappingURL=voice_interface.js.map